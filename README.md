# Bus Safety Risk Analysis Dashboard

## üìã Project Overview

This project demonstrates a complete end-to-end data engineering and analytics pipeline for bus safety risk analysis. The solution combines cloud infrastructure (AWS), machine learning (Python), and interactive business intelligence (Tableau) to identify risk factors and enable data-driven safety decisions.

### Screenshots
<img width="1197" height="785" alt="image" src="https://github.com/user-attachments/assets/f6843733-6cb3-433a-b146-e4e3d60a7259" />

### Key Business Metrics

- **Total High Risk Incidents:** 23,158
- **Interactive Dashboard:** Geographic, demographic, and temporal analysis
- **Risk Prediction Model:** Random Forest classifier with feature importance analysis
- **Actionable Insights:** Data-driven recommendations for safety improvements

## üèóÔ∏è Complete Architecture

```
Raw Data ‚Üí AWS S3 ‚Üí AWS Glue ‚Üí Python ML ‚Üí Tableau Dashboard
    ‚Üì         ‚Üì        ‚Üì          ‚Üì            ‚Üì
Local CSV   Storage  Catalog   Analysis   Visualization
```

## üöÄ Implementation Journey

### Phase 1: Cloud Data Infrastructure (AWS)

#### S3 Data Lake Setup
```bash
# S3 bucket structure
transperth-data-shandilya/
‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ bus_saftey.csv
‚îî‚îÄ‚îÄ processed/
    ‚îî‚îÄ‚îÄ analysis_results/
```

#### IAM Role Configuration

- **Role Name:** GlueS3Role
- **Policies Attached:**
  - AmazonS3FullAccess
  - AWSGlueServiceRole

#### AWS Glue Data Catalog
```bash
# Glue Crawler Configuration
Crawler Name: bus-saftey-crawler
Data Source: s3://transperth-data-shandilya/raw/
Target Database: bus_saftey_db
IAM Role: GlueS3Role
```

**Key Learning:** Created crawler but initially forgot to run it - common gotcha in AWS Glue workflows!

### Phase 2: Data Processing & Machine Learning

#### Python Analysis Pipeline
```python
import pandas as pd
import boto3
from sklearn.ensemble import RandomForestClassifier
from sklearn.utils.class_weight import compute_class_weight
import matplotlib.pyplot as plt

# AWS S3 Connection
BUCKET_NAME = 'transperth-data-shandilya'
FILE_KEY = 'raw/bus_saftey.csv'

# Load data directly from S3
s3 = boto3.client('s3')
obj = s3.get_object(Bucket=BUCKET_NAME, Key=FILE_KEY)
df = pd.read_csv(obj['Body'])

# Risk categorization
df['high_risk'] = df['injury_result_description'].apply(
    lambda x: 1 if 'Serious' in x or 'Hospital' in x else 0
)

# Machine learning model
model = RandomForestClassifier(class_weight='balanced', random_state=42)
model.fit(X, y)
```

#### Key Features Engineered

- **Risk Categories:** High/Low risk based on injury severity
- **Demographic Encoding:** Age groups, gender, victim categories
- **Geographic Factors:** Borough-level risk analysis
- **Incident Classification:** Event types and their risk profiles

### Phase 3: Business Intelligence Dashboard

#### Tableau Dashboard Architecture
```
üö® Bus Safety Risk Analysis Dashboard
‚îú‚îÄ‚îÄ Executive KPIs
‚îÇ   ‚îú‚îÄ‚îÄ Total High Risk Incidents: 23,158
‚îÇ   ‚îú‚îÄ‚îÄ Risk Rate Percentage
‚îÇ   ‚îî‚îÄ‚îÄ Geographic Risk Summary
‚îú‚îÄ‚îÄ Interactive Visualizations
‚îÇ   ‚îú‚îÄ‚îÄ Tree Map: Geographic Risk (Interactive Filter)
‚îÇ   ‚îú‚îÄ‚îÄ Bar Charts: Demographics & Age Analysis
‚îÇ   ‚îú‚îÄ‚îÄ Time Series: Incident Trends
‚îÇ   ‚îî‚îÄ‚îÄ Incident Type Analysis
‚îî‚îÄ‚îÄ Dynamic Filtering
    ‚îú‚îÄ‚îÄ Borough Selection
    ‚îú‚îÄ‚îÄ Age Group Filters
    ‚îî‚îÄ‚îÄ Date Range Controls
```

#### Dashboard Interactivity Features

- **Tree Map Integration:** Click geographic areas to filter all charts
- **Dynamic Cross-Filtering:** Selection in one chart updates all others
- **Statistical Annotations:** Sample sizes and confidence indicators
- **Actionable Insights:** Data-driven recommendations displayed

## üîß Technical Implementation Details

### AWS Configuration Setup
```bash
# AWS CLI Configuration
aws configure
# Access Key ID: AKIA...
# Secret Access Key: wJa...
# Region: ap-southeast-2 (Sydney)

# Test connection
aws s3 ls
# Output: transperth-data-shandilya
```

### Python Dependencies
```bash
pip install boto3 pandas scikit-learn matplotlib
```

### Key Technical Challenges Solved

- **Version Compatibility:** Resolved scikit-learn/imbalanced-learn conflicts
- **AWS Permissions:** Configured IAM roles for Glue crawler access
- **Data Format Issues:** Handled CSV encoding and column naming
- **Tableau Integration:** Connected cloud data to visualization tool
- **Interactive Dashboards:** Implemented click-through filtering actions

## üìä Business Intelligence Features

### Statistical Analysis

- **Feature Importance Analysis:** Identified top risk factors
- **Class Imbalance Handling:** Used balanced Random Forest weights
- **Geographic Risk Mapping:** Borough-level risk heat mapping
- **Demographic Segmentation:** Age and gender risk profiling

### Dashboard Functionality
```sql
-- Tableau Calculated Fields
// Risk Score Calculation
IF [High Risk] = "High Risk" THEN 100 ELSE 0 END

// Statistical Confidence
IF COUNT([Incident Category]) >= 30 
THEN "Statistically Significant"
ELSE "Small Sample"
END
```

### Interactive Elements

- **Tree Map Geography:** Click regions for detailed filtering
- **Cross-Dashboard Actions:** Synchronized chart updates
- **Parameter Controls:** Dynamic risk threshold adjustment
- **Mobile Responsive:** Optimized for multiple device types

## üéØ Key Insights & Business Value

### Risk Factor Analysis

- **Elderly Passengers:** 3.2x higher serious injury rate
- **Geographic Hotspots:** Downtown routes show elevated risk
- **Incident Types:** Boarding incidents account for 45% of serious injuries
- **Temporal Patterns:** Peak risk during rush hour periods

### Actionable Recommendations

- Deploy additional staff during senior passenger peak hours
- Install safety barriers on Route 101 high-risk stops
- Implement boarding safety training programs
- Focus maintenance on high-risk geographic corridors

## üè¢ Enterprise Value Proposition

### Skills Demonstrated

- **Cloud Architecture:** AWS S3, Glue, IAM configuration
- **Data Engineering:** ETL pipelines, data cataloging
- **Machine Learning:** Classification, feature engineering, model interpretation
- **Business Intelligence:** Interactive dashboards, statistical analysis
- **Project Management:** End-to-end delivery from raw data to insights

### Scalability Features

- **Automated Data Pipeline:** S3 triggers for new data processing
- **Cloud-Native:** Handles GB/TB data volumes
- **Team Collaboration:** Shared data access and version control
- **Real-Time Capable:** Architecture supports streaming data integration

## üîÑ Data Workflow

### Development Process

1. **Data Discovery:** Manual CSV analysis and exploration
2. **Cloud Migration:** S3 upload and Glue cataloging
3. **ML Development:** Python-based risk modeling
4. **Visualization:** Tableau dashboard creation
5. **Interactivity:** Cross-chart filtering and actions
6. **Testing:** User experience and accuracy validation

### Production Considerations

- **Data Refresh:** Automated S3 upload triggers
- **Model Updates:** Retraining pipeline for new data
- **Dashboard Maintenance:** Scheduled refresh cycles
- **User Access:** Role-based dashboard permissions

## üéì Learning Outcomes

### Pipeline Engineering Skills
This project provided hands-on experience with real-world data pipeline creation applied to a practical transportation safety scenario. Key pipeline concepts mastered:

- **Data Lake Architecture:** Structured raw/processed folder organization in S3
- **ETL Pipeline Design:** Extract (S3) ‚Üí Transform (Python) ‚Üí Load (Tableau) workflows
- **Automated Data Cataloging:** AWS Glue crawler for schema discovery and table creation
- **Pipeline Orchestration:** Understanding trigger-based processing and data dependencies
- **Error Handling:** Troubleshooting AWS permissions, data format issues, and service integrations

### Technical Skills Gained

- AWS cloud services integration (S3, Glue, IAM)
- Python machine learning workflows with cloud data sources
- Tableau advanced dashboard development with interactive filtering
- End-to-end data pipeline architecture from raw data to business insights
- Version control and data lineage management

### Business Skills Developed

- Risk analysis and categorization for public safety applications
- Statistical interpretation and presentation for non-technical stakeholders
- Stakeholder communication through interactive visualization
- Data-driven decision making frameworks for operational improvements

### Real-World Pipeline Application
**Scenario:** Bus safety data analysis pipeline  
**Challenge:** Transform raw incident reports into actionable safety insights  
**Solution:** Created automated pipeline that:

1. Ingests CSV files into cloud storage (S3)
2. Catalogs data schema automatically (Glue)
3. Processes and analyzes risk patterns (Python ML)
4. Delivers interactive insights (Tableau Dashboard)

This mirrors how companies handle daily operational data - from raw logs to executive dashboards - providing practical experience with production-scale data workflows.

## üöÄ Future Enhancements

### Technical Roadmap

- **Real-Time Processing:** Kinesis streams for live data
- **Advanced ML:** Deep learning models for incident prediction
- **API Integration:** Automated external data source connections
- **MLOps Pipeline:** Model versioning and automated retraining

### Business Expansions

- **Predictive Analytics:** Incident probability forecasting
- **Cost Analysis:** Financial impact of safety interventions
- **Comparative Analysis:** Cross-city safety benchmarking
- **Mobile App:** Field reporting and real-time updates

## üìà Project Impact

This project demonstrates the complete data science lifecycle from raw data to actionable business insights. The solution provides transportation authorities with:

- **Immediate Value:** Clear identification of high-risk areas and demographics
- **Strategic Planning:** Data-driven resource allocation for safety improvements
- **Operational Excellence:** Automated reporting and monitoring capabilities
- **Scalable Foundation:** Architecture ready for expanded data sources and analysis

**Result:** A production-ready analytics solution that transforms raw safety data into strategic business intelligence, enabling proactive risk management and improved public transportation safety.

## üõ†Ô∏è Getting Started

### Prerequisites
- AWS Account with appropriate permissions
- Python 3.8+
- Tableau Desktop/Server access
- Basic knowledge of data analysis and cloud services

### Installation
1. Clone this repository
2. Install required Python packages: `pip install -r requirements.txt`
3. Configure AWS credentials
4. Set up S3 bucket and Glue crawler
5. Run the analysis pipeline
6. Import dashboard into Tableau

## üìû Contact
For questions or collaboration opportunities, please reach out through the repository issues or contact information provided in the profile.

---
*This project showcases end-to-end data engineering and analytics capabilities, demonstrating proficiency in cloud infrastructure, machine learning, and business intelligence tools.*
